\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{graphicx}
\author{Fabian Alenius,Chongyang Sun, Kjell Winblad} 
\title{Two steps }
\begin{document}
\maketitle


\section{Describe HMM, short overview}
For pattern recognition problem, like handwritten image recognition, there has  always been some randomness and uncertainty from the source recognition data. Stocastic modeling is known to deal with these problem efficiently by using probabilistic models[111].  Among such stochastic approaches, Hidden Markov Models have been widely used to model dynamic signals.
The Hidden Markov Model treats the data as a sequence of observations, while consisting hidden states connected to each other by transition probabilities.
 
An HMM is characterized by the following[Rabiner]:
\begin{enumerate}
\item	N, the number of states in the model.
\item	M, the number of distinct observation symbols per state.
\item	A, the transition probability distribution.
\item	B, the observation symbol probability distribution in state
\item	Pi, the initial state distribution.
\end{enumerate}

In contrast to knowledge-based approach, HMMs use statistical algorithms that can automatically extract knowledge from the samples. Also, HMMs model the pattern implicitly by different paths in the stochastic work. The strength of modeling power can be enhanced by showing more samples[modeling and recognition of cursive words with hidden markov models]\cite{customer}.

\section{Implementation Issues}

While implementing HMM for both character recognition and word recognition, we encounter some practical issues.

\subsection{Initial Model Selection}
%4.1. Describe the different initialization algos, advantages and disadvantages. Chongyang


Hidden Markov models can be efficiently trained by Baum Welch algorithm, which is an iterative process for estimating parameters for HMMs. As an iterative algorithm, BW starts from an initial model and estimates transition and emission probability parameters by computing expectations via Forward and Backward, which sums over all paths containing a given event until convergence is reached.

Since the Baum-Welch algorithm is a local iterative method, the resulting HMM and the number of required iterations depend heavily on the initial model. Of the many ways to generate an initial model, some techniques consider the training data while others do not[R. Durbin, S. Eddy, A. Krogh, G. Mitchison, Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids, Cambridge University Press, Cambridge, 1998.].

According to the paper[Initial model selection for DNA ], we tried the three initialization strategies as well, namely, count-based, random and uniform tested on the training data for character HMM model.

----training is better or not? Kjell?

\subsection{Topology of HMM}

Since EM method assumes that the model is correct, it is important to devise a suitable topology before training starts. The topology of the model is usually built by using a prior knowledge on the data[character book]. Generally, for machine learning or handwriting signals, a left-to-right HMM is often carried out, which no back transitions from right to left are allowed.

\begin{enumerate}
\item	Character classifier: A model is created for each class in the training phase.

Since alphabet in English is limited, up to 26, we can take the cost that each separated model is trained for each character using segmented word images.
Furthermore, We specialized our beginning and ending states denoted by b and e respectively according to one suggested model for training[DNApaper].
Special beginning and ending states are included generally because then the multiple observation training sequences are concatenated together to form one observation sequence for input into the Baum-Welch algorithm[DNApaper].

In the concatenated string, the original segments of character images sequences are connected by the special observation symbols "@" and \$.
 Also the special beginning state always transitions to the first normal state, and the special ending state always transitions to the special beginning state. Then forward and backward algorithm is used to choose the model that has the most probability of the observation sequence. See Figure 1



\item	Word classifier: A single model is constructed for the whole vocabulary. 

Generally itâ€™s natural to implement Hidden Markov Models for each of the word when vocabulary is limited and small. And similar topologies can be found among those HMMs. Then we can also use forward and backward algorithm to choose the most likely model to tell which word it is as what we did for character classifier above. It works really well when we classify the test data to get the results within 20 words as following.

["dog","cat","pig","love","hate","scala","python","summer","winter",\\"night",daydream","nightmare","animal","happiness","sadness","tennis",\\"feminism","fascism","socialism","capitalism"]

However, it is time consuming and not realistic to generate HMMs for every word when the vocabulary is relatively large. Therefore, later on we came up with another HMM topology to ideally describe unconstrained words of mixed style.

To be specific, a Hmm  with a topology that is a complete directed graph is modeled. It has 28 hidden states(26 for 26 letters and 2 for @ and \$). 
Transition matrix is a 28 * 28 matrix, which is estimated from the lexicon analysis. For example if there's only three words in our vocabulary: dog cat cap for "A to T is set to 0.5 and A to P is set to 0.5" and "A to other letters is set to 0".

Each state's observation is the letter we observed from the character classifier in the previous step. For setting the observation probability matrix, it's reasonable to set them to the probabilities from the test results from word classifier. For example, if we have 10 test examples , for A and 5 of them are classified to be A, 3 to B and 2 to C by the character classifier, then P(observation A)=0.5, P(observation B)=0.3 and P(observation C)=0.2. Then we will assign the row for A as"0.5 0.3 0.2 0 0 ......0 0".

\end{enumerate}

\subsection{prevention of underflow}

For sufficiently large t states, forward variable $\textbf{a}_t(i)$ and backward variable  $\textbf{b}_t(i)$ head exponentially to zero and exceed the precision range of computer. The only reasonable way of performing the computation is by incorporating a scaling procedure[rabineer].
For each t, first we compute $\textbf{a}_t(i)$ according to the induction fomula(20) in rabiner's paper ,and then multiply it by a scaling factor  $\textbf{c}_t$, where c is equal to $ \frac{1}{ \displaystyle\sum_{i=1}^N \textbf{a}_t(i)}$.

To escape the underflow situation in viterbi algorithm, in order to give the maximum likelihood state sequence, we can simply adopt adding log probability rather than multiplying probabilities. Then no scaling is required.

\subsection{Handling null transitions}
Another problem may occur when training HMM parameters is that transition probability is very likely to be null. In our implementation, we initialze them to very small number, such as \textbf{ $10^{-10}$}.

\section{Dataset}

Actually, we tried very hard to find datasets of handwritten from the internet at the very beginning. But it turns out many of them are not available. And the rest of them, like following image example(Figure 2), they need very much image processing work before we got down to the core part of our project for this course, like baseline slant normalization, skew correction, skeleton and so on.

Therefore, instead of consuming plenty of time in the preprocessing the datasets, we implement a Graphic User Interface to create data sets by ourselves. The most advantage of this solution is that it records directly one pixel wide letters which the letters are already separated. The crucial part of work, image processing, is reduced significantly.

Furthermore, if the vocabulary is relatively large, we found out it can be easier for us to test our HMM, because our word training data is made up randomly chosen from the 26 character files.


*********************************************************






Equation \ref{eq1} shows how the value vector \textbf{V} is defined in terms of the transition matrix  \textbf{P} and reward vector  \textbf{R} with a finite time horizon T.
The discount factor $d$ sets how much future rewards are discounted when calculating the present value.
\begin{equation}\label{eq1}
\textbf{V}^T = \sum_{t=0}^T  [(1 + d)^{-1} \textbf{P}]^t \cdot \textbf{R}
\end{equation}

When considering an infinite time horizon, the equation changes to Equation \ref{eq2}.
\begin{equation}\label{eq2}
\textbf{V} \equiv \lim_{T \rightarrow \infty} \textbf{V}^T = \{\textbf{I} - (1 + d)^{-1} \cdot \textbf{P} \}^{-1} \cdot \textbf{R}
\end{equation}


Therefore, given the economic and probabilistic assumptions of the model, the firm can evaluate the expected present values from $\textbf{V}$. For example, the last recency with the negative value in the vector $\textbf{V}$ tells that the firm can do relatively better when curtailing its relationships with this customer after such recency.

According to the observation above, one can modify the Markov decision model with ease and reformulate the model easily. One possible way is to use less states and setting $\textbf{p}_t$ with negative values equal to zeros and the corresponding elements $\textbf{r}_t$ in $\textbf{R}$ equal to zeros as well.

Furthermore, whenever purchase probabilities, remarketing expenditures and net contributions depending on recency are considered in the model, MCM can be adjusted to it by expanding the state space and breaking out the original recency 1 state into several new states. The states are  corresponding to the listed affecting factors which depend on customer recency at the time of purchase. 

The MCM can not only be used for customer migration situations, but also for customer retention situations. For customer retention, the firm could start a fairly simple model by assigning MCM to have three states:  Prospect, Customer and Former Customer. 

The last case discussed in the paper illustrates how to apply MCM to a situation where the firm believes that purchase probabilities, net contribution, and remarketing expenditures all depend on the recency, frequency and monetary value of past purchases. The MCM uses states defined by $\textbf{(r, f, m)}$ where the elements are integers with some upper bounds. Particularly, monetary values categories are paid much attention and single last purchase amount is chosen to avoid its non-Markovian nature instead of moving average.




\section{Discussion}

%Write a report on the article. The report must summarize the material (in no more than 2 pages), and then also include your own judgement and ideas. What are the authors main points? Do you agree?

The authors' main purpose with the paper is to show that MCMs can be used to model many different customer relationship scenarios. It is done by some examples of scenarios that can be modeled with MCM. They also show with examples how the models can be used to change a company's relationship policy. They argue that MCMs can be useful due to it's flexibility. This is illustrated by the examples. For example MCMs can be used to model customer retention and customer migration scenarios. One advantage of using MCM for customer relationship problems seem to be that the MCM naturally account for the stochasticity in customer relationships.

The authors do not write anything about the validity of the assumptions underlying the models. For example, they assume that ending a relationship with a customer is to prefer, if the expected value of the customer's future purchases will be less than the cost of the relationship. This and other assumptions made in the models may be oversimplification in some cases. For example if the customer relationship is about sending out commercial, the relatives of the customer might see the commercial, so even if the targeted customer will not purchase anything the relationship might create new customers. However, the purpose of the paper is not to present a very accurate model but to show some use cases of MCMs.

\bibliographystyle{plain}	% (uses file "plain.bst")
\bibliography{myrefs}		% expects file "myrefs.bib"
\end{document}