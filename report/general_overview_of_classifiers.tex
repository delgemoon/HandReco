
The handwriting recognition system has two levels, each containing a classifier. 
The first classifier is a function that takes an image as input and outputs a character. 
The second classifier is a function that takes a string of characters as input and outputs a word.

We have implemented two kinds of word classifiers.
The first one is called \emph{Forward-classifier} and it has exactly the same architecture as the character classifier and is explained in this section.
The second one is called \emph{Viterbi-classifier} and is explained in Section~\ref{sec:word_classifiers}.
A flowchart that shows the classification process can be seen in Figure~\ref{fig:classification_system_overview}. 

    \begin{figure}[htb] 
      \begin{center}
	\leavevmode
	\includegraphics[width=110mm]{classification_system_overview.pdf}%width=115mm,height=40mm
      \end{center}
      \caption{Flowchart of classification process.}
      \label{fig:classification_system_overview}
    \end{figure}

The classifiers contain HMMs for all elements in the set of possible outputs. 
So if the character classifier is trained to recognize the 26 Latin characters, it will contain 26 HMMs. 
When the classifiers are trained they are given input examples for all possible outputs. 
If the input $I$ is given to one of the classifiers the following steps are performed to calculate the output:

\begin{enumerate}
  \item The probability of $I$ is calculated for all HMMs contained in the classifier:
    \begin{enumerate}
      \item $I$ is translated into a sequence of observation symbols $\mathbf{O} = O_{1},O_{2},...,O_{n}$. 
      If $I$ is a string of characters and the output of the classifier is a word, the translation is straightforward. 
      Every character in the string is simply translated to the corresponding observation symbol. 
      There are also special observations for the start and end states. 
      This is explained in more detail in the following sections. 
      If $I$ is an image, the image is first segmented to a sequence of segments. 
      An observation symbol is then obtained from all segments. 
      See section~\ref{sec:image_preprocessing} for more information about the image feature extraction.
      \item The Forward algorithm \cite{Rabiner1989} is then used to calculate the probability of $\mathbf{O}$ given the HMM.
    \end{enumerate}
  \item The output symbol with the highest probability in the previous step is returned as output.
\end{enumerate}
 
 %% I think this sentence should be split up or turned into a list. It's hard to read in its current form imo. --Fabian
The following parameters must be supplied when a classifier is created\footnote{A few more parameters can be given but are not listed here because of lack of importance. See the source code of the system for information about other parameters. How the source code can be obtained is explained in appendix~\ref{app:source_code}.}:
\begin{itemize}
 \item The set of possible output symbols and corresponding training examples.
 \item The initialization method that should be used by the HMMs.
 \item A binary variable, specifying if the training examples should be used to train the model with the Baum-Welch \cite{Rabiner1989} training algorithm.
\end{itemize}
